import os
import feedparser
import google.generativeai as genai
from supabase import create_client
from dotenv import load_dotenv
import datetime
import time
import json
import requests
import random
import dashscope
from http import HTTPStatus

# ================= é…ç½®åŒº =================
load_dotenv()
# os.environ["HTTP_PROXY"] = "http://127.0.0.1:7897" 
# os.environ["HTTPS_PROXY"] = "http://127.0.0.1:7897"

supabase = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))
# å¼•å…¥ transport æ¨¡å—
from google.api_core import client_options as client_options_lib

# é…ç½®è¶…æ—¶æ—¶é—´ä¸º 10 ç§’ (è€Œä¸æ˜¯é»˜è®¤çš„ 600 ç§’)
genai.configure(
    api_key=os.environ.get("GEMINI_API_KEY"),
    transport="rest", # å¼ºåˆ¶ä½¿ç”¨ REST åè®®ï¼Œæœ‰æ—¶å€™èƒ½è§£å†³ gRPC è¿æ¥é—®é¢˜
    client_options=client_options_lib.ClientOptions(
        api_endpoint="generativelanguage.googleapis.com"
    )
)
gemini_model = genai.GenerativeModel('gemini-flash-latest') 
dashscope.api_key = os.environ.get("DASHSCOPE_API_KEY")

# ================= èœå•ä¸ä¿¡æº =================
RSS_SOURCES = {
    "æ”¿æ²»": ["https://www.zaobao.com.sg/rss/news/china", "http://feeds.bbci.co.uk/news/world/rss.xml"],
    "ç»æµ": ["http://www.caixin.com/rss/finance.xml", "https://www.yicai.com/rss/toutiao.xml"],
    "ç§‘æŠ€": ["https://www.36kr.com/feed", "https://sspai.com/feed"],
    "AI":   ["https://www.jiqizhixin.com/rss", "https://www.qbitai.com/feed"]
}

# ================= æ ¸å¿ƒå·¥å…· =================

def fetch_rss_with_headers(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) Chrome/91.0.4472.124 Safari/537.36'}
    try:
        response = requests.get(url, headers=headers, timeout=15)
        response.encoding = 'utf-8'
        return feedparser.parse(response.content)
    except:
        return None

def clean_text(text):
    from bs4 import BeautifulSoup
    try:
        return BeautifulSoup(text, "html.parser").get_text()[:300]
    except:
        return text[:300]

# --- æ™ºèƒ½ AI è°ƒç”¨ (è¿”å›æ–‡æœ¬æˆ–JSON) ---
def call_ai_smart(prompt, return_json=False):
    # å°è¯• Gemini
    try:
        response = gemini_model.generate_content(prompt)
        text = response.text.strip()
        if return_json:
            clean = text.replace("```json", "").replace("```", "").strip()
            return json.loads(clean)
        return text
    except Exception as e:
        print(f"     âš ï¸ Gemini å¤±è´¥ ({e})ï¼Œåˆ‡æ¢é˜¿é‡Œ Qwen...")
        # å°è¯• Qwen
        try:
            proxies = os.environ.copy()
            if "HTTP_PROXY" in os.environ: del os.environ["http://127.0.0.1:7897"]
            if "HTTPS_PROXY" in os.environ: del os.environ["http://127.0.0.1:7897"]
            
            response = dashscope.Generation.call(
                model=dashscope.Generation.Models.qwen_turbo,
                prompt=prompt
            )
            # æ¢å¤ä»£ç†
            os.environ["HTTP_PROXY"] = ["http://127.0.0.1:7897"]
            os.environ["HTTPS_PROXY"] = ["http://127.0.0.1:7897"]

            if response.status_code == HTTPStatus.OK:
                text = response.output.text.strip()
                if return_json:
                    clean = text.replace("```json", "").replace("```", "").strip()
                    return json.loads(clean)
                return text
        except:
            return None

# ================= ä¸šåŠ¡é€»è¾‘ =================

# 1. ç”Ÿæˆæ¯æ—¥å“²ç† (ä¿æŒä¸å˜)
def generate_daily_quote():
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print("âœ¨ ç”Ÿæˆä»Šæ—¥å“²ç†...")
    
    # æŸ¥é‡
    if supabase.table("daily_quotes").select("id").eq("date", today_str).execute().data:
        print("   å·²å­˜åœ¨ï¼Œè·³è¿‡")
        return

    prompt = f"""
    ä»Šå¤©æ˜¯ {today_str}ã€‚éšæœºç”Ÿæˆä¸€æ¡å†…å®¹ï¼š
    1. å†å²ä¸Šçš„ä»Šå¤©å‘ç”Ÿçš„æ·±æ„äº‹ä»¶+ç®€çŸ­è¯„è®ºã€‚
    2. æˆ–ä¸€å¥åäººåè¨€+æ·±åº¦è§£è¯»ã€‚
    è¦æ±‚ï¼šJSONæ ¼å¼ {{"content": "å†…å®¹+è§£è¯»", "author": "ä½œè€…/äº‹ä»¶"}}ï¼Œ150å­—å†…ã€‚
    """
    data = call_ai_smart(prompt, return_json=True)
    if data:
        supabase.table("daily_quotes").insert({
            "date": today_str, "content": data.get("content"), "author": data.get("author")
        }).execute()
        print("   âœ… å“²ç†å…¥åº“")

# 2. ç”Ÿæˆã€åˆ†ç±»é¡µã€‘çš„æ–°é—»å¡ç‰‡ (æ”¿æ²»/ç»æµ/ç§‘æŠ€/AI/æ®µå­)
def generate_category_cards(category):
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"\nğŸ“‚ å¤„ç†åˆ†ç±»å¡ç‰‡: {category} ...")

    # å‡†å¤‡ç´ æ
    materials = []
    if category == "æ®µå­":
        prompt_sys = "ä½ æ˜¯ä¸€ä¸ªå¹½é»˜å¤§å¸ˆã€‚å†™5ä¸ªå¥½ç¬‘çš„æ®µå­æˆ–ç§‘æŠ€åœˆå†·ç¬‘è¯ã€‚"
    else:
        feeds = RSS_SOURCES.get(category, [])
        for url in feeds:
            feed = fetch_rss_with_headers(url)
            if feed and feed.entries:
                for entry in feed.entries[:3]:
                    materials.append(f"æ ‡é¢˜ï¼š{entry.title}\né“¾æ¥ï¼š{entry.link}\næ‘˜è¦ï¼š{clean_text(entry.get('summary',''))}")
        
        if not materials:
            print("   âš ï¸ æ— ç´ æï¼Œè·³è¿‡")
            return
        
        random.shuffle(materials)
        materials = materials[:10]
        prompt_sys = f"ä½ æ˜¯ä¸€ä¸ªæ–°é—»ç¼–è¾‘ã€‚æ ¹æ®ç´ ææ€»ç»“5æ¡æœ€æœ‰ä»·å€¼çš„æ–°é—»ã€‚æ¯æ¡æ–°é—»å†™300å­—å·¦å³çš„æ‘˜è¦ï¼Œå®¢è§‚ã€ç®€æ˜æ‰¼è¦ã€‚"

    # æ„å»º Prompt
    prompt = f"""
    {prompt_sys}
    
    ã€é‡è¦ã€‘è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ï¼Œä¸è¦åŒ…å« Markdown æ ‡è®°ã€‚
    æ ¼å¼ç¤ºä¾‹ï¼š
    [
        {{"title": "æ–°é—»æ ‡é¢˜1", "content": "300å­—æ‘˜è¦...", "url": "åŸå§‹é“¾æ¥", "source": "æ¥æºåª’ä½“"}},
        {{"title": "æ–°é—»æ ‡é¢˜2", "content": "300å­—æ‘˜è¦...", "url": "åŸå§‹é“¾æ¥", "source": "æ¥æºåª’ä½“"}}
    ]
    
    å¯¹äºâ€œæ®µå­â€æ¿å—ï¼Œurl å’Œ source å¯ä»¥ç•™ç©ºã€‚
    
    ç´ æå¦‚ä¸‹ï¼š
    {chr(10).join(materials)}
    """

    cards_json = call_ai_smart(prompt, return_json=True)
    
    if cards_json:
        # å­˜å…¥æ•°æ®åº“ (category=åˆ†ç±»å, cards=JSONæ•°æ®)
        supabase.table("daily_briefs").insert({
            "date": today_str,
            "category": category,
            "cards": cards_json
        }).execute()
        print(f"   âœ… [{category}] å¡ç‰‡å…¥åº“æˆåŠŸ")
        time.sleep(5)

# 3. ç”Ÿæˆã€é¦–é¡µã€‘å…¨ç«™æ€»ç»“
def generate_home_summary():
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print("\nğŸ  ç”Ÿæˆé¦–é¡µå…¨ç«™æ€»ç»“...")
    
    # æ”¶é›†å…¨ç«™ç´ æï¼ˆæ¯ä¸ªåˆ†ç±»æŠ“ä¸€ç‚¹ï¼‰
    all_materials = []
    for cat, feeds in RSS_SOURCES.items():
        for url in feeds:
            feed = fetch_rss_with_headers(url)
            if feed and feed.entries:
                all_materials.append(f"[{cat}] {feed.entries[0].title}")
    
    if not all_materials: return

    prompt = f"""
    ä»Šå¤©æ˜¯ {today_str}ã€‚è¯·æ ¹æ®ä»¥ä¸‹ä»Šæ—¥å…¨çƒæ–°é—»æ ‡é¢˜ï¼Œå†™ä¸€æ®µé«˜åº¦æ¦‚æ‹¬çš„ç»¼è¿°ã€‚
    è¦æ±‚ï¼š
    1. å­—æ•°200å­—å·¦å³ã€‚
    2. åŒ…å«æ”¿æ²»ã€ç»æµã€ç§‘æŠ€ç­‰é¢†åŸŸçš„å…³é”®åŠ¨æ€ã€‚
    3. è¯­è¨€ç²¾è¾Ÿã€æœ‰æ·±åº¦ï¼Œé€‚åˆæ”¾åœ¨é¦–é¡µä½œä¸ºâ€œä»Šæ—¥å¯¼è¯»â€ã€‚
    4. åªè¿”å›çº¯æ–‡æœ¬ã€‚
    
    ç´ æï¼š
    {chr(10).join(all_materials[:15])}
    """
    
    summary = call_ai_smart(prompt, return_json=False)
    if summary:
        supabase.table("daily_briefs").insert({
            "date": today_str,
            "category": "é¦–é¡µ",
            "summary": summary
        }).execute()
        print("   âœ… é¦–é¡µæ€»ç»“å…¥åº“æˆåŠŸ")

if __name__ == "__main__":
    generate_daily_quote()
    
    # å…ˆç”Ÿæˆå„ä¸ªå­ç‰ˆå—
    for cat in RSS_SOURCES.keys():
        generate_category_cards(cat)
    generate_category_cards("æ®µå­")
    
    # æœ€åç”Ÿæˆé¦–é¡µ
    generate_home_summary()
    print("\nğŸ‰ å…¨éƒ¨å®Œæˆ")