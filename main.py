import os
import feedparser
import google.generativeai as genai
from supabase import create_client
from dotenv import load_dotenv
import datetime
import time
import json
import requests
import random
import dashscope
from http import HTTPStatus
from openai import OpenAI
import re

# ================= 1. é…ç½®åŒº =================
load_dotenv()

supabase = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))

genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
gemini_model = genai.GenerativeModel('gemini-flash-latest')

deepseek_client = OpenAI(
    api_key=os.environ.get("DEEPSEEK_API_KEY"), 
    base_url="https://api.deepseek.com"
)

dashscope.api_key = os.environ.get("DASHSCOPE_API_KEY")

PROXY_PORT = "7897" # ä½ çš„VPNç«¯å£

# ================= 2. å¼ºåŠ›ä¿®å¤çš„æ–°é—»æº (è§£å†³æ”¿æ²»ç©ºç™½) =================
RSS_SOURCES = {
    "æ”¿æ²»": [
        # æ¢æˆäº†å›½å†…ç›´è¿æœ€ç¨³çš„ä¸­æ–°ç½‘å’Œæ¾æ¹ƒ
        "https://www.chinanews.com.cn/rss/scroll-news.xml", 
        "https://www.thepaper.cn/rss/jsp?nodeid=25434", # æ¾æ¹ƒæ—¶äº‹
        "http://feeds.bbci.co.uk/news/world/rss.xml"    # ä¿ç•™ä¸€ä¸ªå¤–åª’
    ],
    "ç»æµ": [
        "http://rss.sina.com.cn/news/finance/chinalist.xml",
        "https://feed.36kr.com/tags/finance",
        "https://www.ftchinese.com/rss/news"
    ],
    "ç§‘æŠ€": [
        "https://www.36kr.com/feed",
        "https://sspai.com/feed",
        "https://www.huxiu.com/rss/0.xml"
    ],
    "AI": [
        "https://www.jiqizhixin.com/rss",
        "https://www.qbitai.com/feed",
        "https://rsshub.app/36kr/search/article/AI"
    ]
}

# ================= 3. å…œåº•å›¾åº“ (ä¿æŒä¸å˜) =================
FIXED_IMAGES = {
    "æ”¿æ²»": ["https://images.unsplash.com/photo-1529101091760-6149d4c46b29?w=800&q=80", "https://images.unsplash.com/photo-1575517111839-3a3843ee7f5d?w=800&q=80"],
    "ç»æµ": ["https://images.unsplash.com/photo-1611974765270-ca1258634369?w=800&q=80", "https://images.unsplash.com/photo-1590283603385-17ffb3a7f29f?w=800&q=80"],
    "ç§‘æŠ€": ["https://images.unsplash.com/photo-1518770660439-4636190af475?w=800&q=80", "https://images.unsplash.com/photo-1550751827-4bd374c3f58b?w=800&q=80"],
    "AI":   ["https://images.unsplash.com/photo-1677442136019-21780ecad995?w=800&q=80", "https://images.unsplash.com/photo-1620712943543-bcc4688e7485?w=800&q=80"],
    "æ®µå­": ["https://images.unsplash.com/photo-1505664194779-8beaceb93744?w=800&q=80"]
}

# ================= 4. æ ¸å¿ƒå·¥å…· =================

def set_proxy(enable=True):
    proxy_url = f"http://127.0.0.1:{PROXY_PORT}"
    if enable:
        os.environ["HTTP_PROXY"] = proxy_url
        os.environ["HTTPS_PROXY"] = proxy_url
    else:
        os.environ.pop("HTTP_PROXY", None)
        os.environ.pop("HTTPS_PROXY", None)

def fetch_rss_with_headers(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    try:
        set_proxy(True)
        resp = requests.get(url, headers=headers, timeout=10)
        resp.encoding = 'utf-8'
        return feedparser.parse(resp.content)
    except:
        try:
            set_proxy(False) # å…³ä»£ç†é‡è¯•
            resp = requests.get(url, headers=headers, timeout=10)
            resp.encoding = 'utf-8'
            return feedparser.parse(resp.content)
        except:
            return None

def clean_text(text):
    from bs4 import BeautifulSoup
    try:
        return BeautifulSoup(text, "html.parser").get_text()[:300]
    except:
        return text[:300]

def extract_image_from_entry(entry):
    if 'media_content' in entry and len(entry.media_content) > 0: return entry.media_content[0]['url']
    if 'links' in entry:
        for link in entry.links:
            if 'image' in link.get('type', ''): return link.href
    content = entry.get('summary', '') + entry.get('content', [{'value': ''}])[0].get('value', '')
    match = re.search(r'<img[^>]+src=["\'](http[^"\']+)["\']', content)
    if match: return match.group(1)
    return None

def get_fallback_image(category):
    images = FIXED_IMAGES.get(category, FIXED_IMAGES["ç§‘æŠ€"])
    return random.choice(images)

def is_url_seen(url):
    try:
        res = supabase.table("news_history").select("id").eq("url", url).execute()
        return len(res.data) > 0
    except: return False

def mark_url_seen(url, title):
    try:
        supabase.table("news_history").insert({"url": url, "title": title}).execute()
    except: pass

def call_ai_smart(prompt, return_json=False):
    # 1. Gemini
    try:
        set_proxy(True)
        response = gemini_model.generate_content(prompt, request_options={'timeout': 25})
        text = response.text.strip()
        if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
        return text
    except:
        # 2. DeepSeek
        try:
            set_proxy(False)
            resp = deepseek_client.chat.completions.create(
                model="deepseek-chat", messages=[{"role": "user", "content": prompt}], stream=False
            )
            text = resp.choices[0].message.content.strip()
            if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
            return text
        except:
            # 3. Qwen
            try:
                set_proxy(False)
                resp = dashscope.Generation.call(model=dashscope.Generation.Models.qwen_turbo, prompt=prompt)
                if resp.status_code == HTTPStatus.OK:
                    text = resp.output.text.strip()
                    if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
                    return text
            except:
                return None

# ================= 5. ä¸šåŠ¡é€»è¾‘ (å«å¹´ç»ˆç­–åˆ’) =================

def generate_category_cards(category):
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"\nğŸ“‚ å¤„ç†åˆ†ç±»: {category} ...")

    materials = []
    image_pool = {}

    if category == "æ®µå­":
        prompt_sys = "ä½ æ˜¯ä¸€ä¸ªè„±å£ç§€æ¼”å‘˜ã€‚å†™5ä¸ªå…³äºç§‘æŠ€ã€AIã€èŒåœºã€ç”Ÿæ´»çš„çˆ†ç¬‘æ®µå­ï¼Œé£æ ¼çŠ€åˆ©å¹½é»˜ï¼Œæ‹’ç»è€æ¢—ã€‚æ¯ä¸ªæ®µå­100å­—å·¦å³ã€‚"
    else:
        feeds = RSS_SOURCES.get(category, [])
        for url in feeds:
            feed = fetch_rss_with_headers(url)
            if not feed or not feed.entries: continue
            
            print(f"    âœ… æŠ“å–: {url}")
            for entry in feed.entries:
                link = entry.link
                if is_url_seen(link): continue # å»é‡
                
                title = entry.title
                img = extract_image_from_entry(entry)
                if img: image_pool[title] = img
                
                materials.append(f"æ ‡é¢˜ï¼š{title}\né“¾æ¥ï¼š{link}\næ‘˜è¦ï¼š{clean_text(entry.get('summary',''))}")
                if len(materials) >= 15: break
            if len(materials) >= 15: break

        if not materials:
            print("    âŒ æ— æ–°ç´ æ")
            return
        
        random.shuffle(materials)
        materials = materials[:12]
        prompt_sys = f"ä½ æ˜¯ä¸€ä¸ªæ–°é—»ç¼–è¾‘ã€‚æŒ‘é€‰5æ¡æœ€æœ‰ä»·å€¼çš„ã€{category}ã€‘æ–°é—»ã€‚æ¯æ¡200-300å­—ã€‚"

    prompt = f"""
    {prompt_sys}
    è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ï¼š
    [
        {{"title": "åŸæ ‡é¢˜", "content": "å†…å®¹...", "url": "é“¾æ¥", "source": "æ¥æºåª’ä½“"}}
    ]
    ç´ æï¼š
    {chr(10).join(materials)}
    """

    cards_json = call_ai_smart(prompt, return_json=True)
    
    if cards_json:
        final_cards = []
        for card in cards_json:
            card['image'] = get_fallback_image(category)
            if category != "æ®µå­":
                if card.get('url'): mark_url_seen(card['url'], card['title'])
                for raw_title, raw_img in image_pool.items():
                    if card['title'][:5] in raw_title or raw_title[:5] in card['title']:
                        card['image'] = raw_img
                        break
            final_cards.append(card)

        supabase.table("daily_briefs").insert({
            "date": today_str, "category": category, "cards": final_cards
        }).execute()
        print(f"   ğŸ‰ [{category}] å…¥åº“æˆåŠŸ")
        time.sleep(3)

def generate_daily_quote():
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print("âœ¨ ç”Ÿæˆå“²ç†...")
    if supabase.table("daily_quotes").select("id").eq("date", today_str).execute().data:
        return
    prompt = "éšæœºç”Ÿæˆä¸€å¥å¯Œæœ‰å“²ç†çš„åäººåè¨€æˆ–å†å²ä¸Šçš„ä»Šå¤©ã€‚è¿”å›JSON: {\"content\":..., \"author\":...}"
    data = call_ai_smart(prompt, return_json=True)
    if data:
        supabase.table("daily_quotes").insert({"date": today_str, "content": data.get("content"), "author": data.get("author")}).execute()

# --- æ–°å¢ï¼šå¹´æœ«ç‰¹åˆ«ç­–åˆ’é€»è¾‘ ---
def generate_home_summary():
    today = datetime.datetime.now()
    today_str = today.strftime('%Y-%m-%d')
    print("\nğŸ  ç”Ÿæˆé¦–é¡µã€å¹´ç»ˆç‰¹åˆ«ç‰ˆã€‘...")

    # åˆ¤æ–­æ˜¯å¦æ˜¯æœ€åä¸€å¤©
    if today.month == 12 and today.day == 31:
        # 12æœˆ31æ—¥ï¼šå¹´åº¦ç»ˆææ€»ç»“
        prompt = f"""
        ä»Šå¤©æ˜¯2025å¹´12æœˆ31æ—¥ï¼Œè¿™ä¸€å¹´çš„æœ€åä¸€å¤©ã€‚
        è¯·ä½œä¸ºå†å²è®°å½•è€…ï¼Œå†™ä¸€ç¯‡ã€2025å…¨çƒå¹´åº¦å¤§äº‹ä»¶å›é¡¾ã€‘ã€‚
        è¦æ±‚ï¼š
        1. å®å¤§å™äº‹ï¼Œå›é¡¾ä»Šå¹´åœ¨AIã€åœ°ç¼˜æ”¿æ²»ã€ç»æµã€ç§‘æŠ€é¢†åŸŸçš„é‡Œç¨‹ç¢‘äº‹ä»¶ã€‚
        2. è¯­æ°”æ·±æ²‰ã€å……æ»¡å¸Œæœ›ä¸åæ€ã€‚
        3. å­—æ•°300å­—å·¦å³ã€‚åªè¿”å›çº¯æ–‡æœ¬ã€‚
        """
    else:
        # å¹³å¸¸æ—¥ï¼šéšæœºé€‰å–å¹´åº¦è¯é¢˜
        topics = ["AIé‡å¡‘ä¸–ç•Œ", "å…¨çƒç»æµéœ‡è¡", "å¤ªç©ºæ¢ç´¢æ–°çºªå…ƒ", "åœ°ç¼˜æ”¿æ²»æ ¼å±€", "æ°”å€™ä¸èƒ½æº", "ç”Ÿç‰©ç§‘æŠ€çªç ´"]
        topic = random.choice(topics)
        prompt = f"""
        ä»Šå¤©æ˜¯2025å¹´12æœˆ{today.day}æ—¥ï¼Œä¸´è¿‘å¹´ç»ˆã€‚
        è¯·ä»¥ã€2025å¹´ç»ˆè¯„è¿°ï¼š{topic}ã€‘ä¸ºä¸»é¢˜ï¼Œå†™ä¸€ç¯‡æ·±åº¦çŸ­è¯„ã€‚
        è¦æ±‚ï¼š
        1. å›é¡¾ä»Šå¹´è¯¥é¢†åŸŸçš„å…³é”®å˜åŒ–ã€‚
        2. å±•æœ›2026å¹´çš„è¶‹åŠ¿ã€‚
        3. å­—æ•°250å­—å·¦å³ã€‚
        4. è¯­æ°”ä¸“ä¸šã€æœ‰æ´è§ã€‚åªè¿”å›çº¯æ–‡æœ¬ã€‚
        """

    summary = call_ai_smart(prompt)
    if summary:
        supabase.table("daily_briefs").insert({
            "date": today_str, "category": "é¦–é¡µ", "summary": summary
        }).execute()
        print("   âœ… é¦–é¡µå¹´ç»ˆè¯„è¿°å…¥åº“")

if __name__ == "__main__":
    generate_daily_quote()
    for cat in ["æ”¿æ²»", "ç»æµ", "ç§‘æŠ€", "AI", "æ®µå­"]:
        generate_category_cards(cat)
    generate_home_summary()
    print("\nğŸš€ å…¨éƒ¨å®Œæˆï¼")