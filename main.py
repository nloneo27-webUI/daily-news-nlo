import os
import feedparser
import google.generativeai as genai
from supabase import create_client
from dotenv import load_dotenv
import datetime
import time
import json
import requests
import random
import dashscope
from http import HTTPStatus
from openai import OpenAI
import re
import urllib.parse

# ================= 1. é…ç½®åŒº =================
load_dotenv()

supabase = create_client(os.environ.get("SUPABASE_URL"), os.environ.get("SUPABASE_KEY"))

genai.configure(api_key=os.environ.get("GEMINI_API_KEY"))
gemini_model = genai.GenerativeModel('gemini-flash-latest')

deepseek_client = OpenAI(
    api_key=os.environ.get("DEEPSEEK_API_KEY"), 
    base_url="https://api.deepseek.com"
)

dashscope.api_key = os.environ.get("DASHSCOPE_API_KEY")

# æœ¬åœ°è¿è¡Œæ—¶ä½¿ç”¨ä»£ç†ï¼ŒGitHub Actions ä¸Šè¿è¡Œæ—¶ä¸éœ€è¦
# æˆ‘ä»¬é€šè¿‡æ£€æŸ¥æ˜¯å¦æœ‰ 'GITHUB_ACTIONS' ç¯å¢ƒå˜é‡æ¥åˆ¤æ–­
IS_GITHUB_ACTIONS = os.getenv("GITHUB_ACTIONS") == "true"
PROXY_PORT = "7897"

# ================= 2. ä¼˜åŒ–åçš„ RSS æº =================
RSS_SOURCES = {
    "æ”¿æ²»": [
        "https://www.chinanews.com.cn/rss/scroll-news.xml", # ä¸­æ–°ç½‘ (ç¨³)
        "http://feeds.bbci.co.uk/news/world/rss.xml",       # BBC (GitHub Actionsä¸Šèƒ½æŠ“)
        "https://rsshub.app/zaobao/realtime/china"          # è”åˆæ—©æŠ¥ (RSSHubç‰ˆï¼Œæ›´æ˜“æŠ“)
    ],
    "ç»æµ": [
        "http://www.ftchinese.com/rss/news",                # FT
        "https://rsshub.app/wallstreetcn/news/global",      # åå°”è¡—è§é—»
        "http://rss.sina.com.cn/news/finance/chinalist.xml" # æ–°æµª
    ],
    "ç§‘æŠ€": [
        "https://www.36kr.com/feed",
        "https://sspai.com/feed",
        "https://rsshub.app/36kr/newsflashes"               # 36Kr å¿«è®¯
    ],
    "AI": [
        "https://www.jiqizhixin.com/rss",
        "https://rsshub.app/36kr/search/article/AI",
        "https://www.qbitai.com/feed"
    ]
}

# ================= 3. å·¥å…·å‡½æ•° =================

def set_proxy(enable=True):
    """GitHub Actions ä¸Šç¦ç”¨ä»£ç†ï¼Œæœ¬åœ°æ ¹æ®éœ€è¦å¼€å¯"""
    if IS_GITHUB_ACTIONS:
        return # äº‘ç«¯ç¯å¢ƒè‡ªå¸¦æ¢¯å­ï¼Œä¸éœ€è¦è®¾ä»£ç†

    proxy_url = f"http://127.0.0.1:{PROXY_PORT}"
    if enable:
        os.environ["HTTP_PROXY"] = proxy_url
        os.environ["HTTPS_PROXY"] = proxy_url
    else:
        os.environ.pop("HTTP_PROXY", None)
        os.environ.pop("HTTPS_PROXY", None)

def fetch_rss_with_headers(url):
    headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'}
    try:
        # ç­–ç•¥ï¼šGitHub Actions ç›´æ¥æŠ“ï¼›æœ¬åœ°å…ˆä»£ç†åç›´è¿
        if not IS_GITHUB_ACTIONS: set_proxy(True)
        resp = requests.get(url, headers=headers, timeout=15)
        resp.encoding = 'utf-8'
        return feedparser.parse(resp.content)
    except:
        try:
            if not IS_GITHUB_ACTIONS: set_proxy(False)
            resp = requests.get(url, headers=headers, timeout=15)
            resp.encoding = 'utf-8'
            return feedparser.parse(resp.content)
        except Exception as e:
            print(f"    âŒ è¯»å–å¤±è´¥: {url}")
            return None

def clean_text(text):
    from bs4 import BeautifulSoup
    try: return BeautifulSoup(text, "html.parser").get_text()[:300]
    except: return text[:300]

def extract_image_from_entry(entry):
    """å°è¯•æå–åŸå›¾"""
    try:
        if 'media_content' in entry and entry.media_content: return entry.media_content[0]['url']
        content = entry.get('summary', '') + str(entry.get('content', ''))
        match = re.search(r'<img[^>]+src=["\'](http[^"\']+)["\']', content)
        if match: return match.group(1)
    except: pass
    return None

def generate_ai_image_url(prompt_text):
    """
    ä½¿ç”¨ Pollinations.ai ç”Ÿæˆå›¾ç‰‡
    æ— éœ€ Keyï¼Œå…è´¹ï¼Œæ ¹æ® prompt ç”Ÿæˆ
    """
    safe_prompt = urllib.parse.quote(prompt_text)
    # æ ·å¼ï¼šrealistic (å†™å®), width: 800, height: 600
    return f"https://image.pollinations.ai/prompt/{safe_prompt}?width=800&height=600&model=flux&seed={random.randint(1,1000)}"

# --- æ™ºèƒ½ AI è°ƒç”¨ ---
def call_ai_smart(prompt, return_json=False):
    # Gemini
    try:
        if not IS_GITHUB_ACTIONS: set_proxy(True)
        response = gemini_model.generate_content(prompt, request_options={'timeout': 30})
        text = response.text.strip()
        if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
        return text
    except:
        # DeepSeek
        try:
            if not IS_GITHUB_ACTIONS: set_proxy(False)
            resp = deepseek_client.chat.completions.create(model="deepseek-chat", messages=[{"role": "user", "content": prompt}], stream=False)
            text = resp.choices[0].message.content.strip()
            if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
            return text
        except:
            # Qwen
            try:
                if not IS_GITHUB_ACTIONS: set_proxy(False)
                resp = dashscope.Generation.call(model=dashscope.Generation.Models.qwen_turbo, prompt=prompt)
                if resp.status_code == HTTPStatus.OK:
                    text = resp.output.text.strip()
                    if return_json: return json.loads(text.replace("```json", "").replace("```", "").strip())
                    return text
            except: return None

# ================= 5. ä¸šåŠ¡é€»è¾‘ =================

def generate_category_cards(category):
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print(f"\nğŸ“‚ å¤„ç†åˆ†ç±»: {category} ...")

    materials = []
    image_pool = {}

    if category == "æ®µå­":
        prompt_sys = "ä½ æ˜¯ä¸€ä¸ªè„±å£ç§€æ¼”å‘˜ã€‚å†™5ä¸ªå…³äºç§‘æŠ€ã€AIã€èŒåœºã€ç”Ÿæ´»çš„çˆ†ç¬‘æ®µå­ã€‚"
    else:
        feeds = RSS_SOURCES.get(category, [])
        for url in feeds:
            feed = fetch_rss_with_headers(url)
            if not feed or not feed.entries: continue
            print(f"    âœ… æŠ“å–: {url} - {len(feed.entries)}æ¡")
            for entry in feed.entries[:5]: # å¤šæŠ“ç‚¹
                title = entry.title
                img = extract_image_from_entry(entry)
                if img: image_pool[title] = img
                materials.append(f"æ ‡é¢˜ï¼š{title}\né“¾æ¥ï¼š{entry.link}\næ‘˜è¦ï¼š{clean_text(entry.get('summary',''))}")

    # å¦‚æœå®åœ¨æ²¡ç´ æï¼Œå¦‚æœæ˜¯æ®µå­å°±ç¡¬å†™ï¼Œå¦‚æœæ˜¯æ–°é—»å°±è·³è¿‡
    if not materials and category != "æ®µå­":
        print("    âŒ æ— ç´ æ")
        return
        
    random.shuffle(materials)
    materials = materials[:15]
    
    prompt_sys = f"ä½ æ˜¯ä¸€ä¸ªèµ„æ·±æ–°é—»ä¸»ç¼–ã€‚æŒ‘é€‰5æ¡æœ€æœ‰ä»·å€¼çš„ã€{category}ã€‘æ–°é—»ã€‚"

    # ã€å…³é”®å‡çº§ã€‘è¦æ±‚ AI è¿”å› image_prompt (è‹±æ–‡ç»˜å›¾æç¤ºè¯)
    prompt = f"""
    {prompt_sys}
    
    ã€é‡è¦ã€‘è¯·ä¸¥æ ¼è¿”å› JSON æ•°ç»„æ ¼å¼ã€‚
    å¯¹äºæ¯æ¡æ–°é—»ï¼Œè¯·ç”Ÿæˆä¸€ä¸ª `image_prompt` (è‹±æ–‡)ï¼Œæè¿°æ–°é—»ç”»é¢ï¼Œç”¨äºAIç»˜å›¾ã€‚
    ä¾‹å¦‚ï¼š "A futuristic robot shaking hands with a human, realistic style, 8k"
    
    æ ¼å¼ï¼š
    [
        {{
            "title": "ä¸­æ–‡æ ‡é¢˜",
            "content": "300å­—ä¸­æ–‡æ‘˜è¦...",
            "url": "åŸå§‹é“¾æ¥",
            "source": "æ¥æºåª’ä½“",
            "image_prompt": "An abstract 3d render of artificial intelligence neural network, blue and orange lighting"
        }}
    ]
    
    ç´ æå¦‚ä¸‹ï¼š
    {chr(10).join(materials)}
    """

    cards_json = call_ai_smart(prompt, return_json=True)
    
    if cards_json:
        final_cards = []
        for card in cards_json:
            # 1. ä¼˜å…ˆç”¨åŸå›¾ (å¦‚æœèƒ½åŒ¹é…åˆ°)
            has_original_image = False
            if category != "æ®µå­":
                for raw_title, raw_img in image_pool.items():
                    if card['title'][:5] in raw_title or raw_title[:5] in card['title']:
                        card['image'] = raw_img
                        has_original_image = True
                        break
            
            # 2. å¦‚æœæ²¡æœ‰åŸå›¾ï¼Œæˆ–è€…æ¿å—æ˜¯æ®µå­ï¼Œä½¿ç”¨ AI ç”Ÿæˆå›¾
            if not has_original_image:
                img_prompt = card.get('image_prompt', f"{category} news abstract concept art")
                # æ‹¼æ¥ Pollinations URL
                card['image'] = generate_ai_image_url(img_prompt)
            
            final_cards.append(card)

        # åˆ æ‰ä»Šå¤©çš„æ—§æ•°æ®ï¼Œé˜²æ­¢é‡å¤
        supabase.table("daily_briefs").delete().eq("date", today_str).eq("category", category).execute()
        
        supabase.table("daily_briefs").insert({
            "date": today_str, "category": category, "cards": final_cards
        }).execute()
        print(f"   ğŸ‰ [{category}] å…¥åº“æˆåŠŸ (AIé…å›¾å·²ç”Ÿæˆ)")
        time.sleep(3)

def generate_daily_quote():
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print("âœ¨ ç”Ÿæˆå“²ç†...")
    # å…è®¸æ¯å¤©æ›´æ–°è¦†ç›–
    supabase.table("daily_quotes").delete().eq("date", today_str).execute()
    
    prompt = "éšæœºç”Ÿæˆä¸€å¥å¯Œæœ‰å“²ç†çš„åäººåè¨€æˆ–å†å²ä¸Šçš„ä»Šå¤©ã€‚è¿”å›JSON: {\"content\":..., \"author\":...}"
    data = call_ai_smart(prompt, return_json=True)
    if data: supabase.table("daily_quotes").insert({"date": today_str, "content": data.get("content"), "author": data.get("author")}).execute()

def generate_home_summary():
    today_str = datetime.datetime.now().strftime('%Y-%m-%d')
    print("\nğŸ  ç”Ÿæˆé¦–é¡µæ€»ç»“...")
    supabase.table("daily_briefs").delete().eq("date", today_str).eq("category", "é¦–é¡µ").execute()
    
    today = datetime.datetime.now()
    if today.month == 12 and today.day >= 24:
        prompt = f"ä»Šå¤©æ˜¯2025å¹´12æœˆ{today.day}æ—¥ã€‚å†™ä¸€ç¯‡250å­—çš„ã€2025å¹´ç»ˆç§‘æŠ€ä¸ä¸–ç•Œå±€åŠ¿è¯„è¿°ã€‘ã€‚åªè¿”å›çº¯æ–‡æœ¬ã€‚"
    else:
        prompt = "å†™ä¸€æ®µ200å­—çš„ä»Šæ—¥å…¨çƒæ–°é—»ç»¼è¿°ã€‚"
    
    summary = call_ai_smart(prompt)
    if summary:
        supabase.table("daily_briefs").insert({"date": today_str, "category": "é¦–é¡µ", "summary": summary}).execute()

if __name__ == "__main__":
    generate_daily_quote()
    for cat in ["æ”¿æ²»", "ç»æµ", "ç§‘æŠ€", "AI", "æ®µå­"]: generate_category_cards(cat)
    generate_home_summary()
    print("\nğŸš€ å…¨éƒ¨å®Œæˆï¼")